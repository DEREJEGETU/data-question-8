{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.stats import stats\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import urllib.request\n",
    "import os\n",
    "from os.path import join, getsize\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize, tokenize\n",
    "import estnltk\n",
    "\n",
    "p = pd.read_csv('../data/share_repurchase_paragraphs.csv')\n",
    "f = pd.read_csv('../data/nc_validation_filings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Identify share repurchase activity in 10-K or 10-Q docs_\n",
    "\n",
    "> ##### For clarity, there won’t necessarily be separate paragraphs for each of those 7 data points we’ve identified (e.g., Share Repurchase Authorization Date, Share Repurchase Authorization, Share Repurchase Intention, etc.) - you could find each of those 7 data points all in a single paragraph depending on the disclosure in the filing. So if it made sense to, you could look at the problem in two stages - first, identifying those paragraphs generally that are about share repurchases, and second, classifying the data inside the paragraph into those 7 categories.\n",
    "\n",
    "> ##### For the deliverable, please prepare a csv file with the data points that are included in share_repurchase_paragraphs.csv\n",
    "\n",
    "> ##### For errors, we’d prefer to err on the side of a false positive. I think those will also make for easier feedback than negative cases.\n",
    "\n",
    "> ##### Other Relevant Files\n",
    "> #####  1.  nc_training_filings.zip, which contains the HTML filings for each of the items in the training set CSV we sent over (which I believe is a set of 500). That CSV includes accession_number, and all the HTML filings in that archive are named <accession_number>.html .\n",
    "> #####  2.  nc_validation_filings.zip, which contains the HTML filings for an extra 100 filings that aren’t in the training set. These are in case your students want to be able to try their models out on some unmarked data - we’ll provide feedback on those if they do.\n",
    "> #####  3.  nc_validation_filings.csv, which contains the ticker and accession number for the filings in #2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>accession_number</th>\n",
       "      <th>data_key_friendly_name</th>\n",
       "      <th>text</th>\n",
       "      <th>data_value</th>\n",
       "      <th>reported_data_value</th>\n",
       "      <th>reported_units</th>\n",
       "      <th>paragraph_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-17-000018</td>\n",
       "      <td>Share Repurchase Authorization Date</td>\n",
       "      <td>May 28, 2015</td>\n",
       "      <td>20150528</td>\n",
       "      <td>20200000.00</td>\n",
       "      <td>ones</td>\n",
       "      <td>On May 28, 2015 we  announced that our board  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-17-000018</td>\n",
       "      <td>Share Repurchase Authorization</td>\n",
       "      <td>The 2015 share repurchase program authorizes t...</td>\n",
       "      <td>1140000000</td>\n",
       "      <td>1.14</td>\n",
       "      <td>billions</td>\n",
       "      <td>On May 28, 2015 we  announced that our board  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-17-000018</td>\n",
       "      <td>Share Repurchase Intention</td>\n",
       "      <td>remaining authorization to repurchase up to</td>\n",
       "      <td>610000000</td>\n",
       "      <td>610.00</td>\n",
       "      <td>millions</td>\n",
       "      <td>Table of Contents   2016, upon the completion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-17-000018</td>\n",
       "      <td>Share Repurchase Count</td>\n",
       "      <td>repurchased</td>\n",
       "      <td>4100000</td>\n",
       "      <td>4.10</td>\n",
       "      <td>millions</td>\n",
       "      <td>Table of Contents   2016, upon the completion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-17-000018</td>\n",
       "      <td>Amount Spent on Share Repurchases</td>\n",
       "      <td>repurchased</td>\n",
       "      <td>194000000</td>\n",
       "      <td>194.00</td>\n",
       "      <td>millions</td>\n",
       "      <td>Table of Contents   2016, upon the completion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAL</td>\n",
       "      <td>0000006201-18-000009</td>\n",
       "      <td>Share Repurchase Authorization Date</td>\n",
       "      <td>July 2014</td>\n",
       "      <td>20140715</td>\n",
       "      <td>20100000.00</td>\n",
       "      <td>ones</td>\n",
       "      <td>4. Share Repurchase Programs and Dividends   S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAL</td>\n",
       "      <td>0000006201-18-000009</td>\n",
       "      <td>Share Repurchase Authorization</td>\n",
       "      <td>share repurchase programs aggregating</td>\n",
       "      <td>11000000000</td>\n",
       "      <td>11.00</td>\n",
       "      <td>billions</td>\n",
       "      <td>4. Share Repurchase Programs and Dividends   S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAL</td>\n",
       "      <td>0000006201-18-000009</td>\n",
       "      <td>Share Repurchase Intention</td>\n",
       "      <td>remained unused under a repurchase program</td>\n",
       "      <td>450000000</td>\n",
       "      <td>450.00</td>\n",
       "      <td>millions</td>\n",
       "      <td>4. Share Repurchase Programs and Dividends   S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AAL</td>\n",
       "      <td>0000006201-18-000009</td>\n",
       "      <td>Share Repurchase Count</td>\n",
       "      <td>repurchased</td>\n",
       "      <td>33900000</td>\n",
       "      <td>33.90</td>\n",
       "      <td>millions</td>\n",
       "      <td>During the year ended  December 31, 2017,  we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAL</td>\n",
       "      <td>0000006201-18-000009</td>\n",
       "      <td>Amount Spent on Share Repurchases</td>\n",
       "      <td>repurchased</td>\n",
       "      <td>1600000000</td>\n",
       "      <td>1.60</td>\n",
       "      <td>billions</td>\n",
       "      <td>During the year ended  December 31, 2017,  we ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker      accession_number               data_key_friendly_name  \\\n",
       "0      A  0001090872-17-000018  Share Repurchase Authorization Date   \n",
       "1      A  0001090872-17-000018       Share Repurchase Authorization   \n",
       "2      A  0001090872-17-000018           Share Repurchase Intention   \n",
       "3      A  0001090872-17-000018               Share Repurchase Count   \n",
       "4      A  0001090872-17-000018    Amount Spent on Share Repurchases   \n",
       "5    AAL  0000006201-18-000009  Share Repurchase Authorization Date   \n",
       "6    AAL  0000006201-18-000009       Share Repurchase Authorization   \n",
       "7    AAL  0000006201-18-000009           Share Repurchase Intention   \n",
       "8    AAL  0000006201-18-000009               Share Repurchase Count   \n",
       "9    AAL  0000006201-18-000009    Amount Spent on Share Repurchases   \n",
       "\n",
       "                                                text   data_value  \\\n",
       "0                                       May 28, 2015     20150528   \n",
       "1  The 2015 share repurchase program authorizes t...   1140000000   \n",
       "2        remaining authorization to repurchase up to    610000000   \n",
       "3                                        repurchased      4100000   \n",
       "4                                        repurchased    194000000   \n",
       "5                                          July 2014     20140715   \n",
       "6              share repurchase programs aggregating  11000000000   \n",
       "7         remained unused under a repurchase program    450000000   \n",
       "8                                        repurchased     33900000   \n",
       "9                                        repurchased   1600000000   \n",
       "\n",
       "   reported_data_value reported_units  \\\n",
       "0          20200000.00           ones   \n",
       "1                 1.14       billions   \n",
       "2               610.00       millions   \n",
       "3                 4.10       millions   \n",
       "4               194.00       millions   \n",
       "5          20100000.00           ones   \n",
       "6                11.00       billions   \n",
       "7               450.00       millions   \n",
       "8                33.90       millions   \n",
       "9                 1.60       billions   \n",
       "\n",
       "                                      paragraph_text  \n",
       "0  On May 28, 2015 we  announced that our board  ...  \n",
       "1  On May 28, 2015 we  announced that our board  ...  \n",
       "2  Table of Contents   2016, upon the completion ...  \n",
       "3  Table of Contents   2016, upon the completion ...  \n",
       "4  Table of Contents   2016, upon the completion ...  \n",
       "5  4. Share Repurchase Programs and Dividends   S...  \n",
       "6  4. Share Repurchase Programs and Dividends   S...  \n",
       "7  4. Share Repurchase Programs and Dividends   S...  \n",
       "8  During the year ended  December 31, 2017,  we ...  \n",
       "9  During the year ended  December 31, 2017,  we ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I've been tasked with the data engineering process to generate the data to be used in our model. \n",
    "p.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1781 entries, 0 to 1780\n",
      "Data columns (total 8 columns):\n",
      "ticker                    1781 non-null object\n",
      "accession_number          1781 non-null object\n",
      "data_key_friendly_name    1781 non-null object\n",
      "text                      1781 non-null object\n",
      "data_value                1781 non-null int64\n",
      "reported_data_value       1781 non-null float64\n",
      "reported_units            1781 non-null object\n",
      "paragraph_text            1781 non-null object\n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 111.4+ KB\n"
     ]
    }
   ],
   "source": [
    "p.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On May 28, 2015 we  announced that our board  of directors had approved a  new share repurchase program  (the   \"2015 repurchase program\"). The 2015 share repurchase program authorizes the purchase of up to $1.14  billion   of our common stock at the company\\'s discretion  through and including November 1, 2018. The 2015  repurchase   program does  not require  the company  to  acquire a  specific number  of  shares and  may be  suspended  or   discontinued at any time. During the year ended October 31,                                                        95'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.paragraph_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Parcing Item 8 up to the exhibts from a sample filing_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with just one html file in order to manually parse all the elements before item 8 out of file. \n",
    "# It does not look like these html files will be parceable with beautifulsoup. \n",
    "filename = '0000002969-17-000039.html'\n",
    "request = urllib.request.Request('file:///C:/Users/carmijh0/Desktop/Data_Science/Q8/data/nc_training_filings/'+filename)\n",
    "result = urllib.request.urlopen(request)\n",
    "resulttext = result.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results in all the text from the html file\n",
    "soup_test = BS(resulttext, 'html.parser')\n",
    "soup_test.prettify();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(soup_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying soup.get_text() to make a massive string and use regex to separate item 8\n",
    "soup_text = soup_test.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281149"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ITEM 8 begins here\n",
    "soup_text.find('FINANCIAL STATEMENTS AND SUPPLEMENTARY DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528264"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopping at the exhibts \n",
    "soup_text.find('EXHIBITS AND FINANCIAL STATEMENT SCHEDULES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_text_parsed = soup_text[281149:528264]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(soup_text_parsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247115"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup_text_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Identifying share repurchase paragraphs via texttiling tokenization_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word tokenization\n",
    "test_tok_word = word_tokenize(soup_text_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 instances of repurchase in this filling.\n",
    "test_tok_word.count('repurchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tok_word.count('ASR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found one of em\n"
     ]
    }
   ],
   "source": [
    "keyword_list = ['repurchase', 'ASR']\n",
    "if any(word in test_tok_word for word in keyword_list):\n",
    "    print('found one of em')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting to use the Estonian Natural Language Processing... Seems to be some sort of install issue. Can't recognize \"Tokenizer().\"\n",
    "# https://github.com/estnltk/estnltk\n",
    "# tokenizer = estnltk.Tokenizer()\n",
    "# test_tok_para = tokenizer.tokenize(soup_text_parsed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can I tokenize the sample str into paragraphs? \n",
    "ttt = nltk.tokenize.TextTilingTokenizer()\n",
    "para_list = ttt.tokenize(soup_text_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(para_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Identifying specific paragraph where the repurchase is mentioned\n",
    "counter = 0\n",
    "for p in para_list:\n",
    "    p_token = word_tokenize(p)\n",
    "    if \"repurchase\" in p_token:\n",
    "        counter += 1\n",
    "        print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove paragraphs from the list that don't contain repurchase\n",
    "approved = ['repurchase','ASR']\n",
    "refined_list = [para for para in para_list if any(instance in para for instance in approved)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n\\n18. CAPITAL STOCK\\nCommon Stock\\nAuthorized common stock consists of 300\\nmillion shares with a par value of $1 per share. As of 30 September 2017, 249 million shares were issued, with 218 million\\noutstanding.\\nOn 15 September 2011, the Board of Directors authorized the repurchase of up\\nto $1,000 of our outstanding common stock. We repurchase\\nshares pursuant to Rules 10b5-1 and 10b-18 under the Securities Exchange Act of 1934, as amended, through\\nrepurchase agreements established with several brokers. We did not purchase any of our outstanding shares\\nduring fiscal year 2017. At 30 September 2017,\\n$485.3 in share repurchase authorization remains.\\nThe following table reflects the changes in common shares:']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'll need to remove '/n's' and any other html elements from the final list of paragraphs.\n",
    "refined_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Creating a pipeline to isolate all paragraph instances of repurchase within all the supplied fillings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_pargraphs(file):\n",
    "    t = nltk.tokenize.TextTilingTokenizer()\n",
    "    p_list = t.tokenize(file)\n",
    "    return p_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(\"../data/nc_training_filings_test\", topdown=True):\n",
    "    for name in files:\n",
    "        filename = name\n",
    "        request = urllib.request.Request('file:///C:/Users/carmijh0/Desktop/Data_Science/Q8/data/nc_training_filings_test/'+filename)\n",
    "        result = urllib.request.urlopen(request)\n",
    "        resulttext = result.read()\n",
    "        soup = BS(resulttext, 'html.parser')\n",
    "        soup = soup.get_text()\n",
    "        html_file = split_into_pargraphs(soup)\n",
    "        p_list = p_list.append(list(html_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
